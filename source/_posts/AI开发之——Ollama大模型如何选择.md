---
title: AI开发之——Ollama大模型如何选择
categories:
  - 开发
  - Q-AI
  - Ollama
tags:
  - Ollama
abbrlink: d18ef80e
date: 2025-07-16 09:08:09
---
## 一 概述

* 推荐排名
* 最推荐模型
* 模型使用示例
* 补充建议

<!--more-->

## 二 推荐排名

|    模型名称(Ollama可用)    |   参数量   | 日常对话能力 | 编程能力 |   中文支持    |        是否推荐        |
| :------------------------: | :--------: | :----------: | :------: | :-----------: | :--------------------: |
|      LLaMA3 8B / 70B       |  8B / 70B  |    ⭐⭐⭐⭐☆     |  ⭐⭐⭐⭐☆   |     ⭐⭐⭐⭐      |       ✅ 强烈推荐       |
|       Code LLaMA 13B       |    13B     |      ⭐⭐      |  ⭐⭐⭐⭐⭐   |  ⭐⭐(需英文)   |     ✅ 代码专用推荐     |
| DeepSeek-Coder 6.7B / 33B  | 6.7B / 33B |     ⭐⭐⭐      |  ⭐⭐⭐⭐☆   |      ⭐⭐⭐      |     ✅ 适合中英代码     |
| Mistral 7B / Mixtral 12x7B |  7B / MoE  |     ⭐⭐⭐⭐     |   ⭐⭐⭐⭐   |      ⭐⭐⭐      |     ✅ 通用场景推荐     |
|    Phi-3 (mini / small)    | 3.8B / 7B  |     ⭐⭐⭐⭐     |   ⭐⭐⭐⭐   |     ⭐⭐⭐⭐      |       ✅ 轻量可用       |
|        Yi-34B Chat         |    34B     |     ⭐⭐⭐⭐     |   ⭐⭐⭐⭐   | ⭐⭐⭐⭐⭐(强中文) |    ✅ 中文环境强推荐    |
| WizardLM / Qwen / Baichuan |   7B-13B   |     ⭐⭐⭐⭐     |   ⭐⭐⭐    |     ⭐⭐⭐⭐      | ✅ 中文友好，可替代方案 |

## 三 最推荐模型

### 3.1 若注重代码能力 + 通用性

|        选项        |         优点          |                        说明                         |
| :----------------: | :-------------------: | :-------------------------------------------------: |
|  LLaMA3 8B / 70B   |    编程 + 问答全能    |      Meta 出品，性能接近 GPT-3.5，70B 需强显卡      |
| DeepSeek-Coder 33B | 超强代码理解 + 多语言 | 开源最强代码模型之一，支持 Python/JS/Java/Kotlin 等 |
|   Code LLaMA 13B   |   代码生成/解释专业   |          英文提示效果极佳，适合纯代码任务           |

### 3.2 若你希望中文表现优秀 + 代码还行

|        模型        |                    特点                    |
| :----------------: | :----------------------------------------: |
|    Yi-34B Chat     | 强中文理解，代码处理不俗，近似 ChatGPT 3.5 |
| Qwen-7B / Qwen-14B |     阿里出品，中文表现好，代码中等偏上     |
| Baichuan2-13B Chat |         中文问答很强，代码能力适中         |

### 3.3 若你设备配置较低(≤16GB 内存)

|        模型        |                 推荐格式                  |
| :----------------: | :---------------------------------------: |
| Phi-3-mini (3.8B)  | 量化 gguf（Q4_K_M）格式，适合普通笔电运行 |
|     Mistral 7B     |     通用模型中资源消耗最小但效果很强      |
| LLaMA3 8B (Q4量化) |       Ollama 默认支持，问答表现优秀       |

## 四 模型使用示例

### 4.1 安装(如使用 LLaMA3)

```
ollama pull llama3
ollama run llama3
```

### 4.2 提问示例

```
用 Java 写一个多线程下载器
```

## 五 补充建议

|               情景                |                       推荐方案                        |
| :-------------------------------: | :---------------------------------------------------: |
|     想在本地跑 GPT-4 等效模型     |      可尝试 **LLaMA3 70B**（需高端显卡）或云部署      |
|       想要轻量运行 + 写代码       |    **Phi-3** 或 **Mistral 7B**（gguf 量化）很适合     |
|         对中文问答要求高          |              **Yi-34B** 或 **Qwen-14B**               |
| 想全离线 + 翻译 + 代码 + 对话全能 | 配置多模型组合（如 `llama3 + nllb + faster-whisper`） |

